决策树算法
1.优缺点：
	1.1优点：
	计算复杂度不高，输出结果易于理解（具有很强的可解释性，这一点DL不具备，一般商业中需要算法的可解释性），对中间值的缺失不敏感，可以处理不相关特征数据。
	1.2缺点：
	可能会产生过度匹配的问题（Overfit）
2.适用数据类型：
	数值型和标称型
3.原理：
	3.1数据划分
	找到数据集中哪个特征在划分数据分类时起决定性作用。评估每一个特征，根据特征将原始数据集划分成几个数据子集，每一个数据子集都在这个特征的一个分支上。如果某个分支下的数据都属于同一类型，则对类型进行了正确的划分，无需进一步分割。每一次的分解都是一个递归的过程，直到所有类别均处于一个数据子集中。
	3.2信息增益
	划分数据集的原则：将无序的数据变得有序。
	划分数据集前后信息发生的变化成为信息增益。获得信息增益最高的特征就是最好的选择。
	数据的信息：
	l(xi) = - log2p(xi)
	p(xi)是选择该分类的概率
	熵
	数据中所有类别所包含的信息期望值
	H = -∑p(xi)log2p(xi)
	